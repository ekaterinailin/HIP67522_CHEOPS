{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "\n",
    "from math import factorial\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # read phases from file\n",
    "    tess_phases = np.loadtxt(\"../data/tess_phases.txt\")\n",
    "    cheops_phases = np.loadtxt(\"../data/cheops_phases.txt\")\n",
    "\n",
    "    # weigh by observing cadence\n",
    "    weights = np.concatenate([np.ones_like(cheops_phases) * 10. / 60. / 60. / 24., np.ones_like(tess_phases) * 2. / 60. / 24.] )\n",
    "    obs_phases = np.concatenate([cheops_phases, tess_phases])\n",
    "\n",
    "    # flare phases\n",
    "    phases = np.array([0.61248919, 0.81165721, 0.01788908, 0.0296636,  0.05760315, 0.04067287,\n",
    "    0.73005547, 0.94878914, 0.11323833, 0.20031473, 0.15087211, 0.04514247,\n",
    "    0.02527212, 0.05657772, 0.06247738, ]) \n",
    "\n",
    "    # shift by 0.5\n",
    "    obs_phases = (obs_phases + 0.5) % 1\n",
    "    phases = (phases + 0.5) % 1\n",
    "\n",
    "    # define binning\n",
    "    nbins = 100\n",
    "    bins = np.linspace(0, 1, nbins)\n",
    "    binmids= (bins[1:] + bins[:-1]) / 2\n",
    "\n",
    "    # bin the phases\n",
    "    arr = np.digitize(obs_phases, bins)\n",
    "\n",
    "    # sum the observing times in each bin to binned weights\n",
    "    # unit of entries in binned is [days]\n",
    "    binned = np.array([np.sum(weights[arr==i]) for i in range(1, len(bins))]) \n",
    "\n",
    "    # define the two models we want to compare\n",
    "    def modulated_model(binmids, lambda0, lambda1, phase0, dphase, weight=binned):\n",
    "        mask = (binmids > phase0) & (binmids < (phase0 + dphase)%1)\n",
    "        result = np.zeros_like(binmids)\n",
    "\n",
    "        # multiply by weight because that modifies the measured rate\n",
    "        result[~mask] = lambda0 * weight[~mask]\n",
    "        result[mask] = lambda1 * weight[mask]\n",
    "\n",
    "        return result #number of observed flares per bin\n",
    "\n",
    "    def unmodulated_model(lambda0, weight=binned):\n",
    "        return lambda0 * weight #number of observed flares per bin\n",
    "\n",
    "    # observed:\n",
    "    hist, bins = np.histogram(phases, bins=bins)\n",
    "    # define the factorials for the numbers in hist for the likelihood computation\n",
    "    factorials = np.array([factorial(h) for h in hist])\n",
    "\n",
    "    # Poisson log-likelihood function\n",
    "    def log_likelihood_poisson(rate, hist, factorials):\n",
    "        logs = -rate - np.log(factorials) + np.log(rate) * hist\n",
    "        return np.sum(logs)\n",
    "\n",
    "    # log-likelihood for the modulated model\n",
    "    def log_likelihood_mod(params):\n",
    "\n",
    "        rate = modulated_model(binmids, *params, weight=binned)\n",
    "\n",
    "        return log_likelihood_poisson(rate, hist, factorials)\n",
    "\n",
    "    def log_prior_mod(params):\n",
    "        if ((params[0] > 0) & (params[1] > 0) & (params[1] < 5) & ( params[0] < 5) &\n",
    "            (params[2] > 0) & (params[2] < 1) & (params[3] > 0) & (params[3] < 1) ):\n",
    "            return np.log(1/np.sqrt(params[0])) + np.log(1/np.sqrt(params[1])) \n",
    "        return -np.inf\n",
    "\n",
    "    # define log-probability\n",
    "    def log_probability_mod(params):\n",
    "        lp = log_prior_mod(params)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + log_likelihood_mod(params)\n",
    "\n",
    "    # define log-likelihood, prior, and probability\n",
    "    def log_likelihood_unmod(params):\n",
    "        lambda0 = params[0]\n",
    "        rate = unmodulated_model(lambda0, weight=binned)\n",
    "        return log_likelihood_poisson(rate, hist, factorials)\n",
    "    \n",
    "    def log_prior_unmod(params):\n",
    "        if ((params[0] > 0) & (params[0] < 10)):\n",
    "            return np.log(1/np.sqrt(params[0]))\n",
    "        return -np.inf\n",
    "\n",
    "    def log_probability_unmod(params):\n",
    "        lp = log_prior_unmod(params)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + log_likelihood_unmod(params)\n",
    "\n",
    "    ranged =  [5, 10, 300, 300, 80, 80]\n",
    "    # ranged =  [5, 10, 400, 200, 50, 50]\n",
    "    # ranged = [5, 10, 300, 200, 50, 50]\n",
    "\n",
    "\n",
    "\n",
    "    lambda0max, lambda1max, lambda0n, lambda1n, phi0n, dphin = ranged\n",
    "    phi0 = np.linspace(0, 1, phi0n)\n",
    "    dphi = np.linspace(0, 1, dphin)\n",
    "    lambda0s = np.linspace(0, lambda0max, lambda0n)\n",
    "    lambda1s = np.linspace(0, lambda1max, lambda1n)\n",
    "    logls = np.zeros((lambda0n,lambda1n,phi0n, dphin))\n",
    "    for i in range(lambda0n):\n",
    "        print(i)\n",
    "        for j in range(lambda1n):\n",
    "            for k in range(phi0n):\n",
    "                for l in range(dphin):\n",
    "                    logl = log_probability_mod([lambda0s[i], lambda1s[j], phi0[k], dphi[l]])\n",
    "                    logls[i, j, k, l] = logl\n",
    "    integral = np.trapz(np.trapz(np.trapz(np.trapz(np.exp(logls), dphi), phi0), lambda1s), lambda0s) # trapz integrates over the last axis\n",
    "\n",
    "    logsunmod = np.zeros(lambda0n)\n",
    "    for i in range(lambda0n):\n",
    "        logl = log_probability_unmod([lambda0s[i]])\n",
    "        logsunmod[i] = logl\n",
    "    integralunmod = np.trapz(np.exp(logsunmod), lambda0s)\n",
    "\n",
    "    bayes_factor = integral / integralunmod\n",
    "\n",
    "\n",
    "    with open(f\"../results/bayes_factor_{nbins}.txt\", \"a\") as f:\n",
    "        string = f\"{nbins},{lambda0max},{lambda1max},{lambda0n},{lambda1n},{phi0n},{dphin},{bayes_factor},{integral},{integralunmod}\\n\"\n",
    "        f.write(string)\n",
    "        print(string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def compute_log_probability(args):\n",
    "    i, j, k, l = args\n",
    "    logl = log_probability_mod([lambda0s[i], lambda1s[j], phi0[k], dphi[l]])\n",
    "    return i, j, k, l, logl\n",
    "\n",
    "# Create a grid of indices to compute\n",
    "indices = [(i, j, k, l) for i in range(lambda0n) \n",
    "            for j in range(lambda1n) \n",
    "            for k in range(phi0n) \n",
    "            for l in range(dphin)]\n",
    "\n",
    "logls = np.zeros((lambda0n, lambda1n, phi0n, dphin))\n",
    "\n",
    "# Use a ProcessPoolExecutor to parallelize the computation\n",
    "with ProcessPoolExecutor(max_workers=16) as executor:\n",
    "    for result in executor.map(compute_log_probability, indices):\n",
    "        i, j, k, l, logl = result\n",
    "        logls[i, j, k, l] = logl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
